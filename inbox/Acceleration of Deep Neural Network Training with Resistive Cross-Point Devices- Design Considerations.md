### Abstract
최근 몇 년 동안 심층신경망(DNN)은 음성 인식, 시각적 물체 감지, 패턴 추출 등과 같은 대규모 분석 및 분류 작업에서 상당한 비즈니스 영향력을 입증했습니다.
그러나 대규모 DNN의 훈련은 일반적으로 시간이 많이 소요되고 계산 집약적인 작업으로 간주되어 매일 데이터 센터 규모의 컴퓨팅 리소스가 필요한 것으로 알려져 있습니다.
이 논문에서는 적은 전력을 사용하면서 잠재적으로 크기 단위로 DNN 트레이닝을 가속화할 수 있는 저항 처리 장치(RPU) 개념을 제안합니다.
제안된 RPU 장치는 무게 값을 로컬에 저장하고 업데이트할 수 있으므로 트레이닝 중 데이터 이동을 최소화하고 트레이닝 알고리즘의 로컬리티와 병렬성을 충분히 활용할 수 있습니다.
실제 CMOS 호환 기술에서 DNN 훈련용 가속기 칩을 구현하기 위한 장치 및 시스템 수준 사양에 따라 다양한 RPU 장치의 기능/비기능 및 시스템 매개변수의 성능을 평가합니다.
약 10억 개의 무게가 나가는 대형 DNN의 경우, 병렬RPU 아키텍처는 최신 마이크로프로세서에 비해 30,000배의 가속율을 달성하는 동시에 84,000GigaOps/s/W의 전력 효율을 제공할 수 있습니다.
현재 수천 대의 머신이 있는 데이터센터 규모의 클러스터에서 일일 단위의 소프트 트레이닝이 필요한 문제를 단일 RPU 가속기로 몇 시간 내에 해결할 수 있습니다.
클러스터로 구성된 시스템은 자연어 음성 인식 및 전 세계 언어 간 번역, 대규모 비즈니스 스트림에 대한 실시간 분석 및 과학과 같은 현재로서는 해결이 불가능한 수조 개의 파라미터를 가진 빅데이터 문제를 해결할 수 있습니다.