Tayfun Gokmen's RPU Paper: 아날로그 메모리 소자 기반의 인공지능 연산을 위한 기본 소자 스펙 연구 논문
### Abstract
최근 몇 년 동안 심층신경망(DNN)은 음성 인식, 시각적 물체 감지, 패턴 추출 등과 같은 대규모 분석 및 분류 작업에서 상당한 비즈니스 영향력을 입증했습니다. 그러나 대규모 DNN의 훈련은 일반적으로 시간이 많이 소요되고 계산 집약적인 작업으로 간주되어 매일 데이터 센터 규모의 컴퓨팅 리소스가 필요한 것으로 알려져 있습니다. 이 논문에서는 적은 전력을 사용하면서 잠재적으로 크기 단위로 DNN 트레이닝을 가속화할 수 있는 저항 처리 장치(RPU) 개념을 제안합니다. 제안된 RPU 장치는 무게 값을 로컬에 저장하고 업데이트할 수 있으므로 트레이닝 중 데이터 이동을 최소화하고 트레이닝 알고리즘의 로컬리티와 병렬성을 충분히 활용할 수 있습니다. 실제 CMOS 호환 기술에서 DNN 훈련용 가속기 칩을 구현하기 위한 장치 및 시스템 수준 사양에 따라 다양한 RPU 장치의 기능/비기능 및 시스템 매개변수의 성능을 평가합니다. 약 10억 개의 무게가 나가는 대형 DNN의 경우, 병렬RPU 아키텍처는 최신 마이크로프로세서에 비해 30,000배의 가속율을 달성하는 동시에 84,000GigaOps/s/W의 전력 효율을 제공할 수 있습니다. 현재 수천 대의 머신이 있는 데이터센터 규모의 클러스터에서 일일 단위의 소프트 트레이닝이 필요한 문제를 단일 RPU 가속기로 몇 시간 내에 해결할 수 있습니다. 클러스터로 구성된 시스템은 자연어 음성 인식 및 전 세계 언어 간 번역, 대규모 비즈니스 스트림에 대한 실시간 분석 및 과학과 같은 현재로서는 해결이 불가능한 수조 개의 파라미터를 가진 빅데이터 문제를 해결할 수 있습니다.

### introduction
심층 신경망(DNN; LeCun 외.,2015)은 음성(Hinton 외.,2012) 및 사물 인식(Krizhevskyetal.,2012; SimonyanandZisserman,2015; Szegedyetal.,2015)에서 정교한 기존 방법을 뛰어넘는 성능으로 최근 몇 년 동안 상당한 상업적 성공을 거두었습니다. 그러나 DNN을 훈련시키는 것은 매우 계산 집약적인 작업으로 막대한 계산 자원과 엄청난 시간이 필요하기 때문에 추가 적용을 방해한다. 예를 들어, 10억 개의 연결을 가진 DNN의 경우 1000대의 기계로 클러스터를 훈련시킨 결과 70%의 상대적 개선이 입증되었다(Leetal.,2012). 본질적으로 국소적이고 병렬적인 역전파 알고리즘에 의존하는 DNN을 훈련(Rumelhartetal.,1986 ).90년대 초부터 이러한 지역성과 병렬성을 활용하는 다양한 하드웨어적 접근방법이 시도되어 왔으며(아리마에탈.,1991;레만탈.,1993), 현재 개발되고 있는 다양한 하드웨어적 접근방법은 이러한 지역성과 병렬성을 활용하는 DNN트레이닝을 가속화하기 위한 것이다, 1993)부터 현재 GPU(Coatesetal.,2013; Wuetal.,2015), FPGA(Guptaetal.,2015) 또는 특별히 설계된 ASIC(ChenY.etal.,2014)으로 개발되고 있으며, 알고리즘의 근접성과 병렬성을 충분히 활용하면 더욱 가속화할 수 있습니다. N개의 뉴런을 N개의 뉴런에 매핑하는 완전히 연결된 DNN 레이어의 경우, 로컬 스토리지와 노드의 가중치 처리를 사용하여 데이터 이동을 최소화하고 노드를 서로 연결하여 대규모 N × N 수축기 배열로 연결함으로써 상당한 가속화를 달성할 수 있습니다(Lehmannetal.,1993). ), 여기서 전체DNN이 들어갈 수 있으며, 실제 시간적 복잡성인 O(N2) 대신 어레이 크기에 관계없이 즉각적인 시간 O(1)로 문제를 해결할 수 있지만, 해결 가능한 문제 크기는 어레이의 노드 수에 제한이 있기 때문에 최첨단 CMOS 기술로 10억 개까지 확장하기는 어렵습니다. 새로운 나노 전자 소자 개념 기반의 비휘발성 메모리(NVM) 기술인 상변화 메모리(PCM; Jacksonetal.,2013;Kuzumetal.,2013) 및 저항성 랜덤 액세스 메모리(RRAM; Jo etal.,2010;Indiverietal, 2013;쿠즈메탈, 2013;유에탈, 2013;사이히에탈, 2015)는 생물학적 시스템에서 관찰되는 스파이크 타이밍 의존 가소성(STDP)에서 영감을 얻은 학습 규칙으로 신경망을 구현하기 위해 최근에 연구되었습니다(BiandPoo,1998).
최근에야 비로소 역전파 알고리즘을 이용한 DNN 훈련의 가속화를 위한 구현이 고려되고 있으며(Burretal.,2014;Lietal.,2014;Xuetal.,2014;Prezioso etal.,2015;Soudryetal.,2015), 27배(Burretal.,2015)에서 900배(Xu etal.,2014), 심지어 2140배(Seoetal.,2015)까지 보고된 가속 요인으로 가속화가 이루어졌다고 보고되었습니다. ) 및 전력과 면적을 크게 줄일 수 있습니다. 이전에 개발된 메모리 기술을 사용하는 이러한 상향식 접근 방식은 모두 매우 유망해 보이지만 예상되는 가속 계수는 NVM셀로 애플리케이션에 내장된 장치 사양에 따라 제한됩니다. 높은 온/오프 비율, 디지털 비트 현명한 스토리지, 비대칭적인 설정 및 재설정 작업과 같이 일반적으로 유익하거나 관련 없는 것으로 간주되는 디바이스 특성은 DNN 학습 가속화에 제한이 되고 있습니다(Burretal., 2015 유에탈.,2015).이러한 이상적인 디바이스의 특성은 주변 회로와 홀 시스템의 적절한 설계로 잠재적으로 보완될 수 있지만, 부분적으로만 가능하며 작동 시간이 크게 증가하는 비용이 발생한다(Burretal.,2015)
이와는 대조적으로, 본 논문에서는 저항 소자에 대한 특정 요구 사항을 부과하는 시스템 및 CMOS 회로 설계를 통해 DNN 학습의 궁극적인 가속화를 달성하는 하향식 접근 방식을 제안하며, 파운드리 CMOS 기술을 통해 수십억 개의 노드를 동시에 저장 및 처리할 수 있고 잠재적으로 확장 가능한 저항 처리 장치(RPU)의 개념을 제안하고 분석할 것입니다. 기존의 다른 접근 방식(Burretal.,2014, 2015; Lietal.,2014; Xuetal.,2014; Preziosoetal.,2015; Seo etal.,2015; Soudryetal.,2015; Yuetal.,2015. ) 이 분석에서 제안된 최종 디바이스 특성은 단일 디바이스가 추가 회로 구성 요소 없이 알고리즘에 필요한 모든 연산을 수행할 수 있으며, 우리의 추정치는 현실적인 전력과 제약 조건으로 단일 칩에서 30,000배에 가까운 가속 계수를 달성할 수 있음을 나타냅니다.

### MATERIALS AND METHODS : Definition of the RPU Device Concept
역전파 알고리즘은 순방향, 역방향 및 가중치 업데이트의 세 가지 주기로 구성되며, 수렴 기준이 충족될 때까지 여러 번 반복됩니다. 순방향 및 역방향 사이클은 주로 순방향 및 역방향의 벡터 행렬 곱셈을 계산하며, 이 연산은 50여 년 전에 제안된 것처럼 2단 저항 소자의 2D 크로스바레이에서 수행할 수 있습니다(Steinbuch,1961).
순방향 사이클에서는 입력 벡터가 각 입력 행을 통해 전압 펄스로 전송되는 반면, 역방향 사이클에서는 열에서 입력으로 전압 펄스가 공급되면 벡터-매트릭스 곱이 매트릭스 전치로 계산됩니다. 이러한 연산은 필요한 O(1) 시간 복잡성을 달성하지만 훈련 알고리즘의 세 사이클 중 두 사이클에서만 수행됩니다.
순방향 및 역방향 사이클과는 달리, 저항 장치들의 2차원 교차 배열에 대한 가중치 업데이트를 배열 크기와 관계없이 로컬에서 모두 병렬로 구현하는 것은 어렵습니다. 그림 1A에 표시된 것처럼 각 교차점에서 로컬로 수행해야 하는 곱셈 연산과 증분 가중치 업데이트로 구성된 벡터 벡터 외적 곱을 계산해야 하기 때문에 계산이 까다롭습니다. 해당 업데이트 규칙은 일반적으로 다음과 같이 표현됩니다(Rumelhartetal.,1986).

여기서 wij는 i번째 행과 j번째 열의 가중치 값(단순성 계층은 생략)을 나타내고 xi는 입력 뉴런의 활동, δj는 출력 뉴런이 계산한 오류, η는 글로벌 학습률입니다. 가중치 저장 및 처리(RPU)를 모두 수행할 수 있는 두 개의 터미널 장치 배열에서 로컬 및 병렬 업데이트를 구현하려면 먼저 확률적 컴퓨팅 기술을 사용하여 곱셈 연산 자체를 크게 단순화해야 합니다(Gaines,1967;Poppelbaumetal.,1967). AlaghiandHayes,2013;MerkelandKudithipudi,2014), 두 가지 확률적 흐름을 사용함으로써 곱셈 연산을 단순화할 수 있음을 보여주었습니다(Gaines,1967; Poppelbaumetal.,1967;AlaghiandHayes,2013). 그림1B는 뉴런에서 인코딩된 숫자(xi 및 δj)가 확률적 번역기(STR)를 사용하여 확률적 비트 스트림으로 변환되는 가장 확률적인 업데이터룰을 보여줍니다. 이 업데이터룰은 크로스바 배열로 전송되어 각 RPU 디바이스가 xi 및 δj의 비트가 일치할 때 전도도(gij)가 약간 변경되며 이 식에서는 다음과 같이 작성할 수 있습 니다.

여기서 BL은 업데이트 주기 동안 사용되는 STR의 출력에서 가장 우연적인 비트 스트림의 길이이고, 1wmin은 단일 우연 이벤트에 대해 평가된 가중치의 변화, Ani와 Bnj는 베르누이 과정에 의해 특성화되는 임의 변수이며, 위첨자 n은 시험 시퀀스 내 비트 위치를 나타냅니다.
Ani와 Bnj가 동등할 확률은 각각 Cxi와 Cδj에 의해 주어지며, 여기서 C는 다시 STR의 인자입니다. 방정식(2)의 확률적 업데이트를 가능하게 하는 한 가지 가능한 펄스 화학식이 그림 1C에 나와 있습니다. 양수 및 음수 진폭을 갖는 전압 펄스는 각각 해당 STR의 행(Ai)과 열(Bj)에서 나타납니다.
이진 스트림으로 인코딩된 부동 소수점 번호와 반대로, 확률 스트림으로 변환된 해당 번호는 이러한 펄스의 전체 집합으로 표현됩니다. 두 단자 RPU 디바이스가 교차 지점에서 일치 이벤트를 구별하려면 단일 펄스 진폭이 디바이스의 스위칭 전압(VS)의 절반일 때 컨덕턴스 값이 크게 변하지 않아야 하지만 두 펄스가 일치하고 RPU 디바이스가 전체 전압(VS)이 되면 컨덕턴스는 0이 아닌 △gmin만큼 변경되어야 합니다.
파라미터 △gmin은 주변 회로에 의해 정의된 증폭 계수를 통해 △wmin에 비례하며, 그림 1에 표시된 것처럼 업데이트 주기 동안 펄스의 극성을 전환할 수 있도록 전도도의 업/다운 변화를 모두 허용할 수 있습니다. 곱셈의 부호는 업데이터 사이클 동안 사용되는 펄스의 극성에 의해 결정되므로, 부호가 0인 경우 곱셈은 업 및 다운 사이클 동안 모두 xi> 0에 해당하는 열을 채워서 수행될 수 있으며 열은 δj의 부호에 따라 업 사이클과 다운 사이클 중 하나에 선택적으로 채워집니다. 일부 행에 음수 값(xi<0)이 있는 경우 유사한 연산을 반복할 수 있으며, 제안된 펄싱 방식은 배열의 모든 RPU 장치가 우연의 일치 이벤트에 대한 통계에 간단히 의존하여 로컬에서 곱셈 연산을 수행함으로써 훈련 알고리즘의 가중치 업 사이클에 대해 O(1)의 시간 복잡성을 달성할 수 있습니다.
